// ChatComponent.tsx
import './css/ChatComponent.css';
import './css/Sidebar.css';

// Import React
import * as React from 'react';

// Define Message interface with additional types for different message formats
interface Message {
  text: string;
  sender: 'self' | 'bot';
  type?: 'normal' | 'thinking' | 'choice'; // Message type for styling
  choices?: string[]; // For choice messages
}

// Define conversation states
type ConversationState = 
  | 'initial' 
  | 'thinking' 
  | 'agent_selection' 
  | 'information_request' 
  | 'dashboard_response' 
  | 'person_consultation';

// Define agent types
type AgentType = 'sales_support' | 'deal_promotion' | 'technical_consultation';

// SpeechRecognition interfaces are defined in react-app-env.d.ts

const ChatComponent: React.FC = () => {
    const [messages, setMessages] = React.useState<Message[]>([]);
    const [input, setInput] = React.useState('');
    const [isListening, setIsListening] = React.useState(false);
    const [conversationState, setConversationState] = React.useState<ConversationState>('initial');
    const [selectedAgent, setSelectedAgent] = React.useState<AgentType | null>(null);
    const [awaitingChoice, setAwaitingChoice] = React.useState<boolean>(false);
    
    // Create refs to store the SpeechRecognition instance and last result
    const recognitionRef = React.useRef<any>(null);
    const lastResultRef = React.useRef<string>('');
    
    // Initialize speech recognition
    React.useEffect(() => {
      // Check if browser supports SpeechRecognition
      if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {
        console.error('Speech recognition not supported in this browser');
        return;
      }
      
      // Clean up function
      return () => {
        if (recognitionRef.current) {
          recognitionRef.current.stop();
        }
      };
    }, []);
    
    // Send message and process conversation flow
    const sendMessage = () => {
        if (input.trim() === '') return;
        
        // Add user message to chat
        const userMessage = { text: input, sender: 'self' as const };
        setMessages(prev => [...prev, userMessage]);
        
        // Clear input field
        setInput('');
        
        // Process based on conversation state
        switch (conversationState) {
          case 'initial':
            // First user message triggers AI thinking process
            setTimeout(() => {
              // Add thinking process message
              setMessages(prev => [...prev, { 
                text: 'æ€è€ƒä¸­... å–¶æ¥­æ”¯æ´ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã€å•†è«‡æ¨é€²ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã€æŠ€è¡“ç›¸è«‡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹è€ƒãˆã¦ã„ã¾ã™ã€‚', 
                sender: 'bot',
                type: 'thinking'
              }]);
              
              setConversationState('thinking');
              
              // After thinking, suggest an agent
              setTimeout(() => {
                setMessages(prev => [...prev, { 
                  text: 'å–¶æ¥­æ”¯æ´ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚ˆã‚ã—ã„ã§ã™ã­ï¼Ÿ', 
                  sender: 'bot',
                  type: 'choice',
                  choices: ['ã¯ã„', 'ã„ã„ãˆ']
                }]);
                
                setSelectedAgent('sales_support');
                setConversationState('agent_selection');
                setAwaitingChoice(true);
              }, 2000);
            }, 1000);
            break;
            
          case 'information_request':
            // User has provided information request
            setTimeout(() => {
              // Add thinking process for KGI dashboard query
              setMessages(prev => [...prev, { 
                text: 'KGIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«å•ã„åˆã‚ã›ã¦ã„ã¾ã™...', 
                sender: 'bot',
                type: 'thinking'
              }]);
              
              // After "querying", provide response
              setTimeout(() => {
                setMessages(prev => [...prev, { 
                  text: `KGIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«å•ã„åˆã‚ã›ãŸçµæœã€å•†è«‡ã®è¿”ç­”ã¨ã—ã¦ã¯ä»¥ä¸‹ã®æƒ…å ±ãŒã‚ã‚Šã¾ã™ï¼š\n\n${generateDashboardResponse(input)}`, 
                  sender: 'bot'
                }]);
                
                // Ask if user wants to consult with Tone-san
                setTimeout(() => {
                  setMessages(prev => [...prev, { 
                    text: 'åˆ©æ ¹ã•ã‚“ã«èã„ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ', 
                    sender: 'bot',
                    type: 'choice',
                    choices: ['ã¯ã„', 'ã„ã„ãˆ']
                  }]);
                  
                  setConversationState('dashboard_response');
                  setAwaitingChoice(true);
                }, 1000);
              }, 2000);
            }, 1000);
            break;
            
          default:
            // For any other state, just acknowledge
            setTimeout(() => {
              setMessages(prev => [...prev, { 
                text: 'æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚ä»–ã«ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ', 
                sender: 'bot' 
              }]);
            }, 500);
            break;
        }
    };

    // receive message ////api////
    const receiveMessage = () => {
      // Implementation will be added later
    };

    // View messages received  
    const viewMessage = () => {
          setMessages([...messages, { text: 'Hellow!!', sender: 'bot' }]);
          setInput('');   
    };
    
    // Voice input functions
    const startListening = () => {
      const SpeechRecognitionAPI = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      
      if (!SpeechRecognitionAPI) {
        console.error('Speech recognition not supported');
        return;
      }
      
      // If we already have an instance, stop it first
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      
      // Create a new instance and store it in the ref
      recognitionRef.current = new SpeechRecognitionAPI();
      const recognition = recognitionRef.current;
      
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'ja-JP';
      
      // Reset the last result ref when starting a new recognition session
      lastResultRef.current = '';
      
      recognition.onresult = (event: any) => {
        const current = event.resultIndex;
        const transcriptResult = event.results[current][0].transcript;
        
        // Only update if this is a new result
        if (transcriptResult !== lastResultRef.current) {
          lastResultRef.current = transcriptResult;
          setInput((prev) => prev + ' ' + transcriptResult.trim());
        }
      };
      
      recognition.onerror = (event: any) => {
        console.error('Speech recognition error', event.error);
        setIsListening(false);
      };
      
      recognition.onend = () => {
        setIsListening(false);
      };
      
      try {
        recognition.start();
        setIsListening(true);
      } catch (error) {
        console.error('Error starting speech recognition:', error);
      }
    };
    
    const stopListening = () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
        setIsListening(false);
      }
    };
    
    const toggleListening = () => {
      if (isListening) {
        stopListening();
      } else {
        startListening();
      }
    };
    
    // Helper function to generate mock dashboard responses based on user input
    const generateDashboardResponse = (userQuery: string): string => {
      // Simple keyword matching for demo purposes
      if (userQuery.includes('å£²ä¸Š') || userQuery.includes('åç›Š')) {
        return '- ä»Šå››åŠæœŸã®å£²ä¸Š: 1,250ä¸‡å††\n- å‰å¹´åŒæœŸæ¯”: +15%\n- ä¸»è¦é¡§å®¢ã®å£²ä¸Šè²¢çŒ®åº¦: Aç¤¾ 35%, Bç¤¾ 22%, Cç¤¾ 18%';
      } else if (userQuery.includes('é¡§å®¢') || userQuery.includes('ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ')) {
        return '- æ–°è¦é¡§å®¢ç²å¾—æ•°: 12ç¤¾\n- é¡§å®¢æº€è¶³åº¦: 4.2/5.0\n- ä¸»è¦é¡§å®¢ã¨ã®æ¬¡å›ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°: Aç¤¾ 3/15, Bç¤¾ 3/22';
      } else if (userQuery.includes('è£½å“') || userQuery.includes('ã‚µãƒ¼ãƒ“ã‚¹')) {
        return '- ä¸»åŠ›è£½å“ã®è²©å£²çŠ¶æ³: å¥½èª¿\n- æ–°è£½å“ã®ãƒ­ãƒ¼ãƒ³ãƒäºˆå®š: 4æœˆä¸­æ—¬\n- è£½å“æ”¹å–„è¦æœ›ãƒˆãƒƒãƒ—3: UIæ”¹å–„, é€£æºæ©Ÿèƒ½å¼·åŒ–, ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œ';
      } else {
        return '- å–¶æ¥­ãƒãƒ¼ãƒ ã®KPIé”æˆç‡: 87%\n- ä»Šæœˆã®å•†è«‡æˆç´„ç‡: 35%\n- é‡ç‚¹ãƒ•ã‚©ãƒ­ãƒ¼æ¡ˆä»¶: Dç¤¾æ¡ˆä»¶, Eç¤¾ææ¡ˆ, Fç¤¾æ›´æ–°';
      }
    };
    
    // Function to handle newlines in messages for proper display
    const formatMessageText = (text: string): React.ReactNode => {
      return text.split('\n').map((line, i) => (
        <React.Fragment key={i}>
          {line}
          {i < text.split('\n').length - 1 && <br />}
        </React.Fragment>
      ));
    };
    
    // Handle user choice selection
    const handleChoiceSelection = (choice: string, questionText: string) => {
      // Add the user's choice as a message
      setMessages(prev => [...prev, { 
        text: choice, 
        sender: 'self' 
      }]);
      
      // Process the choice based on current conversation state
      if (choice === 'ã¯ã„') {
        switch (conversationState) {
          case 'agent_selection':
            // User confirmed agent selection
            setTimeout(() => {
              setConversationState('information_request');
              setAwaitingChoice(false);
              // Add agent's information request message
              setMessages(prev => [...prev, { 
                text: 'ã©ã†ã„ã£ãŸæƒ…å ±ãŒæ¬²ã—ã„ã§ã™ã‹ï¼Ÿ', 
                sender: 'bot' 
              }]);
            }, 500);
            break;
            
          case 'dashboard_response':
            // User confirmed to consult with Tone-san
            setTimeout(() => {
              setAwaitingChoice(false);
              // Add final response
              setMessages(prev => [...prev, { 
                text: 'åˆ©æ ¹ã•ã‚“ã«å•ã„åˆã‚ã›ã¾ã—ãŸã€‚ã¾ã‚‚ãªãå›ç­”ãŒã‚ã‚Šã¾ã™ã€‚', 
                sender: 'bot' 
              }]);
              // Reset conversation state for next interaction
              setConversationState('initial');
            }, 500);
            break;
            
          default:
            break;
        }
      } else if (choice === 'ã„ã„ãˆ') {
        // Handle "No" responses
        switch (conversationState) {
          case 'agent_selection':
            // User rejected agent selection
            setTimeout(() => {
              setAwaitingChoice(false);
              // Add thinking message for reconsidering agent
              setMessages(prev => [...prev, { 
                text: 'åˆ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ¤œè¨ã—ã¦ã„ã¾ã™...', 
                sender: 'bot',
                type: 'thinking'
              }]);
              
              // Simulate reconsideration and offer new agent
              setTimeout(() => {
                setMessages(prev => [...prev, { 
                  text: 'å•†è«‡æ¨é€²ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ', 
                  sender: 'bot',
                  type: 'choice',
                  choices: ['ã¯ã„', 'ã„ã„ãˆ']
                }]);
                setSelectedAgent('deal_promotion');
                setAwaitingChoice(true);
              }, 1500);
            }, 500);
            break;
            
          case 'dashboard_response':
            // User rejected consulting with Tone-san
            setTimeout(() => {
              setAwaitingChoice(false);
              setMessages(prev => [...prev, { 
                text: 'æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚ä»–ã«ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ', 
                sender: 'bot' 
              }]);
              // Reset conversation state for next interaction
              setConversationState('initial');
            }, 500);
            break;
            
          default:
            break;
        }
      }
    };
    
    return (
        <div id="chat-container">
          <div id="messages">
            {messages.map((msg, index) => {
              if (msg.type === 'choice') {
                return (
                  <div key={index} className="message choice">
                    <div>{msg.text}</div>
                    <div className="choice-buttons">
                      {msg.choices?.map((choice, choiceIndex) => (
                        <button 
                          key={choiceIndex} 
                          className={`choice-button ${choice.toLowerCase() === 'ã¯ã„' ? 'yes' : choice.toLowerCase() === 'ã„ã„ãˆ' ? 'no' : ''}`}
                          onClick={() => handleChoiceSelection(choice, msg.text)}
                        >
                          {choice}
                        </button>
                      ))}
                    </div>
                  </div>
                );
              } else {
                return (
                  <div key={index} className={`message ${msg.sender === 'self' ? 'right' : 'left'} ${msg.type || ''}`}>
                    {formatMessageText(msg.text)}
                  </div>
                );
              }
            })}
          </div>
          <div id="input-container">
            <div className="input-row">
              <input
                type="text"
                value={input}
                onChange={(e) => setInput(e.target.value)}
                onKeyPress={(e) => { 
                  if (e.key === 'Enter' && !awaitingChoice) {
                    e.preventDefault();
                    sendMessage();
                  }
                }}
                placeholder="Type a message..."
                disabled={awaitingChoice}
              />
              <div className="button-container">
                <button onClick={sendMessage} disabled={awaitingChoice}>Send</button>
                <button onClick={toggleListening} className="voice-button" aria-label={isListening ? 'Stop Voice' : 'Voice Message'}>
                  <span className="voice-icon">{isListening ? 'â¹' : 'ğŸ¤'}</span>
                </button>
              </div>
            </div>
          </div>
        </div>
    );
};

export default ChatComponent;
